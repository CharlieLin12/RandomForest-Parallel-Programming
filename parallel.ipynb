{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from decision_tree import DecisionTree\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "class RandomForestClassifier():\n",
    "    \"\"\"\n",
    "    Random Forest Classifier\n",
    "    Training: Use \"train\" function with train set features and labels\n",
    "    Predicting: Use \"predict\" function with test set features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_base_learner=10, max_depth=5, min_samples_leaf=1, min_information_gain=0.0, \\\n",
    "                 numb_of_features_splitting=None, bootstrap_sample_size=None) -> None:\n",
    "        self.n_base_learner = n_base_learner\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_information_gain = min_information_gain\n",
    "        self.numb_of_features_splitting = numb_of_features_splitting\n",
    "        self.bootstrap_sample_size = bootstrap_sample_size\n",
    "        self.total_execution_times = {\n",
    "            \"_create_bootstrap_samples\": 0,\n",
    "            \"train\": 0,\n",
    "            \"_calculate_rf_feature_importance\": 0,\n",
    "            \"predict\": 0,\n",
    "            \"predict_proba\": 0,\n",
    "            \"_predict_proba_w_base_learners\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "    def _create_bootstrap_samples(self, X, Y) -> tuple:\n",
    "        \"\"\"\n",
    "        Creates bootstrap samples for each base learner\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        bootstrap_samples_X = []\n",
    "        bootstrap_samples_Y = []\n",
    "\n",
    "        for i in range(self.n_base_learner):\n",
    "            \n",
    "            if not self.bootstrap_sample_size:\n",
    "                self.bootstrap_sample_size = X.shape[0]\n",
    "            \n",
    "            sampled_idx = np.random.choice(X.shape[0], size=self.bootstrap_sample_size, replace=True)\n",
    "            bootstrap_samples_X.append(X[sampled_idx])\n",
    "            bootstrap_samples_Y.append(Y[sampled_idx])\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"_create_bootstrap_samples\"] += execution_time\n",
    "\n",
    "        return bootstrap_samples_X, bootstrap_samples_Y\n",
    "\n",
    "    def train(self, X_train: np.array, Y_train: np.array) -> None:\n",
    "        start_time = time.time()\n",
    "        \"\"\"Trains the model with given X and Y datasets\"\"\"\n",
    "        bootstrap_samples_X, bootstrap_samples_Y = self._create_bootstrap_samples(X_train, Y_train)\n",
    "\n",
    "        self.base_learner_list = []\n",
    "        for base_learner_idx in range(self.n_base_learner):\n",
    "            base_learner = DecisionTree(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf, \\\n",
    "                                        min_information_gain=self.min_information_gain, \n",
    "                                        numb_of_features_splitting=self.numb_of_features_splitting)\n",
    "            \n",
    "            base_learner.train(bootstrap_samples_X[base_learner_idx], bootstrap_samples_Y[base_learner_idx])\n",
    "            self.base_learner_list.append(base_learner)\n",
    "\n",
    "        # Calculate feature importance\n",
    "        self.feature_importances = self._calculate_rf_feature_importance(self.base_learner_list)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"train\"] += execution_time\n",
    "\n",
    "    def _predict_proba_w_base_learners(self,  X_set: np.array) -> list:\n",
    "        \"\"\"\n",
    "        Creates list of predictions for all base learners\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        pred_prob_list = []\n",
    "        for base_learner in self.base_learner_list:\n",
    "            pred_prob_list.append(base_learner.predict_proba(X_set))\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"_predict_proba_w_base_learners\"] += execution_time\n",
    "        return pred_prob_list\n",
    "\n",
    "    def predict_proba(self, X_set: np.array) -> list:\n",
    "        \"\"\"Returns the predicted probs for a given data set\"\"\"\n",
    "        start_time = time.time()\n",
    "        pred_probs = []\n",
    "        base_learners_pred_probs = self._predict_proba_w_base_learners(X_set)\n",
    "\n",
    "        # Average the predicted probabilities of base learners\n",
    "        for obs in range(X_set.shape[0]):\n",
    "            base_learner_probs_for_obs = [a[obs] for a in base_learners_pred_probs]\n",
    "            # Calculate the average for each index\n",
    "            obs_average_pred_probs = np.mean(base_learner_probs_for_obs, axis=0)\n",
    "            pred_probs.append(obs_average_pred_probs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"predict_proba\"] += execution_time\n",
    "        return pred_probs\n",
    "\n",
    "    def predict(self, X_set: np.array) -> np.array:\n",
    "        \"\"\"Returns the predicted labels for a given data set\"\"\"\n",
    "        start_time = time.time()\n",
    "        pred_probs = self.predict_proba(X_set)\n",
    "        preds = np.argmax(pred_probs, axis=1)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"predict\"] += execution_time\n",
    "        return preds\n",
    "    \n",
    "    def _calculate_rf_feature_importance(self, base_learners):\n",
    "        start_time = time.time()\n",
    "        \"\"\"Calcalates the average feature importance of the base learners\"\"\"\n",
    "        feature_importance_dict_list = []\n",
    "        for base_learner in base_learners:\n",
    "            feature_importance_dict_list.append(base_learner.feature_importances)\n",
    "\n",
    "        feature_importance_list = [list(x.values()) for x in feature_importance_dict_list]\n",
    "        average_feature_importance = np.mean(feature_importance_list, axis=0)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        self.total_execution_times[\"_calculate_rf_feature_importance\"] += execution_time\n",
    "        return average_feature_importance\n",
    "    \n",
    "    def print_time(self) -> None:\n",
    "        print(\"Tổng thời gian thực thi của các phương thức:\")\n",
    "        for method, execution_time in self.total_execution_times.items():\n",
    "            print(f\"{method}: {execution_time} seconds\")\n",
    "\n",
    "    def time_df(self):\n",
    "        components = []\n",
    "\n",
    "        for method, execution_time in self.total_execution_times.items():\n",
    "            components.append({\n",
    "                \"Method\": method,\n",
    "                \"Execution_Time\": execution_time\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame.from_records(components).sort_values(by=[\"Execution_Time\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
